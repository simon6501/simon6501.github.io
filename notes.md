---
layout: page
title: Notes
---

<p class="message">
  Stay tuned for updates! ðŸ˜€ðŸ˜‰
</p>

## Paper notes

### Survey of Multimodality Large Language Models:
A Survey on Multimodal Large Language Models (Tencent YouTu Lab) [arXiv'24](https://arxiv.org/abs/2306.13549)


### Transformer Hardware Accelerator:
TransformerLite: Highefficiency Deployment of Large Language Models on Mobile Phone GPUs (OPPO AI Center) [arXiv'24](https://arxiv.org/abs/2403.20041)

Hardware Accelerator for MultiHead Attention and PositionWise FeedForward in the Transformer [SOCC'20](https://ieeexplore.ieee.org/abstract/document/9524802?casa_token=waZ1VVnVLHsAAAAA:WmpqhJHcrQ1SEubirzdw1WsjJyY9sbh2CNU8kP9LyS_bI1Qx6HRAFsxxdfyXNCWKcUG0rgHxg)

TransPIM: A Memorybased Acceleration via SoftwareHardware CoDesign for Transformer [HPCA'22](https://ieeexplore.ieee.org/abstract/document/9773212?casa_token=LjFoEmvTZk8AAAAA:__alwZqW1r5yDLnv8wfX3_F5EvDJxnzkRtnJcWGFeHkm0202_j5La2jAeO8rTJW2yng8GNroqA)

TransPIM: A Memorybased Acceleration via SoftwareHardware CoDesign for Transformer [ICCAD'21](https://ieeexplore.ieee.org/abstract/document/9643586?casa_token=2d_K8HXHBCsAAAAA:Db1BdFX8JPBQB53rIQjuu2dtmBaxLvoQMiISFyHu19vxvgcRNXdFTKgaKZghaOA3c95dXIcYNQ)

A Survey on Transformer Compression [arXiv'24](https://arxiv.org/html/2402.05964v1)

An Efficient Hardware Accelerator for Sparse Transformer Neural Networks [ISCAS'22](https://ieeexplore.ieee.org/abstract/document/9937659?casa_token=GU_OSiD3EkAAAAA:seTGrT2HRPaad8VXDd7TWvp0FkeSqURil1MCj8xkaEXxWgjqT3dRRVchy08jJlofdL5zm_NCOw)

ViA: A Novel VisionTransformer Accelerator Based on FPGA [Trans CDICS'22](https://ieeexplore.ieee.org/abstract/document/9925700?casa_token=W3nvGlo8ycAAAAA:VXPr0pn1PiJGKR8PpvLdLoAYJs7GK1pEyNm6tDXcH8JyrFUn9EjTcgqg9I1CzCXlHRUEdEIeQ)

Hardware Acceleration of Transformer Networks using FPGAs [PACET'22](https://ieeexplore.ieee.org/abstract/document/9976354)

Accelerating Transformerbased Deep Learning Models on FPGAs using Column Balanced Block Pruning [ISQED'21](https://ieeexplore.ieee.org/abstract/document/9424344?casa_token=OE8jWe4DwcAAAAA:lrw52KTDDBOeCqmtehQVndmbu0L2TE7EoleIaIpy3Oe9__eCqErc2VDLQcmlLZefg0RjfvH6TA)

A length adaptive algorithmhardware codesign of transformer on FPGA through sparse attention and dynamic pipelining [DAC'22](https://dl.acm.org/doi/pdf/10.1145/3489517.3530585)


### Large Language Model Hardware Accelerator:
A Comprehensive Evaluation of FPGABased Spatial Acceleration of LLMs [FPGA'24](https://dl.acm.org/doi/abs/10.1145/3626202.3637600)

Invited Paper: Software/Hardware Codesign for LLM and Its Application for Design Verification [ASPDAC'24](https://ieeexplore.ieee.org/abstract/document/10473893?casa_token=jtqlhEEQSUgAAAAA:nEozyYx6DDfeQL_nR60PHFTIRXJgiXrfOW6qjqOLjD5uhvnzwiiGNnJQ2BTY667WgwsjTEQ)

The Breakthrough Memory Solutions for Improved Performance on LLM Inference (Samsung Electronics) [IEEE Micro Early'24](https://ieeexplore.ieee.org/abstract/document/10477465?casa_token=HIWBOeDFCQAAAAA:tEQsY8r6J8IuhRbLwkHiGALzRfDzzmnI8rfQGitDZANU87VZLSCJxU9qoGJIOnQRN1VwKUTg)

OliVe: Accelerating Large Language Models via Hardwarefriendly OutlierVictim Pair Quantization [ISCA'23](https://dl.acm.org/doi/abs/10.1145/3579371.3589038?casa_token=oC0Xzyuq1qsAAAAA:YUKnbev78hWOmAaDpn5ql0ye7UWCwKsuMPs5M5c13Vc3eo3MvdbSIxX7FCgzOOdW1puKMpuuxhevA)

AWQ: Activationaware Weight Quantization for LLM Compression and Acceleration [arXiv'23](https://arxiv.org/abs/2306.00978)


### Deep Learning & Hardware:
Hardware Accelerator Design for Sparse DNN Inference and Training: A Tutorial (NJU) [Trans Circuits and Systems'24](https://ieeexplore.ieee.org/abstract/document/10365687?casa_token=x1VBz_dINcAAAAA:32cigMkZh4_XTYyq_f7q2xELLdYEeywsEK1oqvxVGutubXuaLGAQNLvYndiJ1CSs6JZE12dA)

